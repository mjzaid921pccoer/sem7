{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HPC.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIl1oHn3PsBm","executionInfo":{"status":"ok","timestamp":1619265961189,"user_tz":-330,"elapsed":978,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"7d374d1d-968a-4397-dbd7-4303c484620a"},"source":["!nvcc --version"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Wed_Jul_22_19:09:09_PDT_2020\n","Cuda compilation tools, release 11.0, V11.0.221\n","Build cuda_11.0_bu.TC445_37.28845127_0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIv_jA15P4Z5","executionInfo":{"status":"ok","timestamp":1619265969427,"user_tz":-330,"elapsed":7255,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"cb073680-2d88-4ded-c28e-ef30cffdb757"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-zopc99r7\n","  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-zopc99r7\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=2d8b7b5534eb4a1b4961c50eb6dafbf277569d08cb4c5b74d8f7de19bbc0054e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_c_oplj3/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9H6CDf_P7D2","executionInfo":{"status":"ok","timestamp":1619265972438,"user_tz":-330,"elapsed":1740,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"0cdad4c4-48b1-4bb6-d177-890052dadce1"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[{"output_type":"stream","text":["created output directory at /content/src\n","Out bin /content/result.out\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k227X6_IRcnN"},"source":["#**HELLO WORLD in CUDA**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KmmGuTqCRrrk","executionInfo":{"status":"ok","timestamp":1619266181161,"user_tz":-330,"elapsed":1620,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"dc76ba2d-5b3e-404d-f480-99ea02b99c87"},"source":["%%cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","#define NUM_BLOCKS 16\n","#define BLOCK_WIDTH 2\n","\n","__global__ void hello(){\n","    printf(\"Hello World from GPU's \\t blockDim:%d \\t blockNo: %d \\t threadNo: %d \\t threadId: %d\\n\",blockDim.x,blockIdx.x,threadIdx.x,(blockDim.x*blockIdx.x+threadIdx.x));\n","}\n","\n","int main() {\n","    printf(\"Hello World from CPU \\n\");\n","    hello<<<NUM_BLOCKS,BLOCK_WIDTH>>>();\n","    cudaDeviceSynchronize(); \n","    return 0;\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Hello World from CPU \n","Hello World from GPU's \t blockDim:2 \t blockNo: 12 \t threadNo: 0 \t threadId: 24\n","Hello World from GPU's \t blockDim:2 \t blockNo: 12 \t threadNo: 1 \t threadId: 25\n","Hello World from GPU's \t blockDim:2 \t blockNo: 15 \t threadNo: 0 \t threadId: 30\n","Hello World from GPU's \t blockDim:2 \t blockNo: 15 \t threadNo: 1 \t threadId: 31\n","Hello World from GPU's \t blockDim:2 \t blockNo: 7 \t threadNo: 0 \t threadId: 14\n","Hello World from GPU's \t blockDim:2 \t blockNo: 7 \t threadNo: 1 \t threadId: 15\n","Hello World from GPU's \t blockDim:2 \t blockNo: 14 \t threadNo: 0 \t threadId: 28\n","Hello World from GPU's \t blockDim:2 \t blockNo: 14 \t threadNo: 1 \t threadId: 29\n","Hello World from GPU's \t blockDim:2 \t blockNo: 10 \t threadNo: 0 \t threadId: 20\n","Hello World from GPU's \t blockDim:2 \t blockNo: 10 \t threadNo: 1 \t threadId: 21\n","Hello World from GPU's \t blockDim:2 \t blockNo: 2 \t threadNo: 0 \t threadId: 4\n","Hello World from GPU's \t blockDim:2 \t blockNo: 2 \t threadNo: 1 \t threadId: 5\n","Hello World from GPU's \t blockDim:2 \t blockNo: 13 \t threadNo: 0 \t threadId: 26\n","Hello World from GPU's \t blockDim:2 \t blockNo: 13 \t threadNo: 1 \t threadId: 27\n","Hello World from GPU's \t blockDim:2 \t blockNo: 9 \t threadNo: 0 \t threadId: 18\n","Hello World from GPU's \t blockDim:2 \t blockNo: 9 \t threadNo: 1 \t threadId: 19\n","Hello World from GPU's \t blockDim:2 \t blockNo: 5 \t threadNo: 0 \t threadId: 10\n","Hello World from GPU's \t blockDim:2 \t blockNo: 5 \t threadNo: 1 \t threadId: 11\n","Hello World from GPU's \t blockDim:2 \t blockNo: 11 \t threadNo: 0 \t threadId: 22\n","Hello World from GPU's \t blockDim:2 \t blockNo: 11 \t threadNo: 1 \t threadId: 23\n","Hello World from GPU's \t blockDim:2 \t blockNo: 8 \t threadNo: 0 \t threadId: 16\n","Hello World from GPU's \t blockDim:2 \t blockNo: 8 \t threadNo: 1 \t threadId: 17\n","Hello World from GPU's \t blockDim:2 \t blockNo: 4 \t threadNo: 0 \t threadId: 8\n","Hello World from GPU's \t blockDim:2 \t blockNo: 4 \t threadNo: 1 \t threadId: 9\n","Hello World from GPU's \t blockDim:2 \t blockNo: 0 \t threadNo: 0 \t threadId: 0\n","Hello World from GPU's \t blockDim:2 \t blockNo: 0 \t threadNo: 1 \t threadId: 1\n","Hello World from GPU's \t blockDim:2 \t blockNo: 6 \t threadNo: 0 \t threadId: 12\n","Hello World from GPU's \t blockDim:2 \t blockNo: 6 \t threadNo: 1 \t threadId: 13\n","Hello World from GPU's \t blockDim:2 \t blockNo: 3 \t threadNo: 0 \t threadId: 6\n","Hello World from GPU's \t blockDim:2 \t blockNo: 3 \t threadNo: 1 \t threadId: 7\n","Hello World from GPU's \t blockDim:2 \t blockNo: 1 \t threadNo: 0 \t threadId: 2\n","Hello World from GPU's \t blockDim:2 \t blockNo: 1 \t threadNo: 1 \t threadId: 3\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IvbkcXoXQEOz"},"source":["---\n","---\n","---\n","# **LP1 - High Performance Computing**\n","**Compute Unified Device Architecture : CUDA**\n","\n","CUDA Programming\n","\n","---\n","# **Assignment 1**\n","a)Implement Parallel Reduction using Min, Max, Sum and Average operations.\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjzYZUrCP-FS","executionInfo":{"status":"ok","timestamp":1619266192351,"user_tz":-330,"elapsed":1633,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"9821c519-f92a-49b3-9da5-8739c92a7188"},"source":["%%cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <math.h>\n","#include <time.h>\n","\n","#define BLOCK_SIZE 64\n","\n","#define SOA 512\n","\n","void randomInit(int* array, int size){\n","  for (int i = 0; i< size; ++i){\n","    //array[i] = rand()%size;\n","    array[i] = i*10;\n","  }\n","}\n","\n","__global__ void kernelReduceMin(int *input, int *results, int n){\n","  __shared__ int sdata[BLOCK_SIZE]; \n","  int i = blockIdx.x * blockDim.x + threadIdx.x;\n","  int tx = threadIdx.x; \n","\n","  int temp = 0; \n","  if(i< n){\n","  temp = input[i]; \n","  sdata[tx] = temp; \n","  }\n","  __syncthreads();\n","\n","  for(int stride = blockDim.x>>1; stride > 0; stride >>= 1){\n","    __syncthreads();\n","   //printf(\"i = %d \\t tx = %d \\t offset = %d \\n\",i,tx,stride);\n","    if(tx< stride){\n","      if(sdata[tx +stride] <sdata[tx]){\n","        sdata[tx] = sdata[tx + stride];\n","      }\n","    }\n","  }\n","  \n","  if(threadIdx.x == 0) \n","  { \n","    results[blockIdx.x] = sdata[0]; \n","  } \n","}\n","\n","__global__ void kernelReduceMax(int *input, int *results, int n){\n","  __shared__ int sdata[BLOCK_SIZE]; \n","  int i = blockIdx.x * blockDim.x + threadIdx.x;\n","  int tx = threadIdx.x; \n","\n","  int temp = 0; \n","  if(i< n){\n","  temp = input[i]; \n","  sdata[tx] = temp; \n","  }\n","  __syncthreads();\n","\n","  for(int stride = blockDim.x>>1; stride > 0; stride >>= 1){\n","    __syncthreads();\n","   //printf(\"i = %d \\t tx = %d \\t offset = %d \\n\",i,tx,stride);\n","    if(tx< stride){\n","      if(sdata[tx +stride] >sdata[tx]){\n","        sdata[tx] = sdata[tx + stride];\n","      }\n","    }\n","  }\n","  \n","  if(threadIdx.x == 0) \n","  { \n","    results[blockIdx.x] = sdata[0]; \n","  } \n","}\n","\n","__global__ void kernelReduceSum(int *input, int *results, int n){\n","  __shared__ int sdata[BLOCK_SIZE]; \n","  int i = blockIdx.x * blockDim.x + threadIdx.x;\n","  int tx = threadIdx.x; \n","\n","  int temp = 0; \n","  if(i< n){\n","  temp = input[i]; \n","  sdata[tx] = temp; \n","  }\n","  __syncthreads();\n","\n","  for(int stride = blockDim.x>>1; stride > 0; stride >>= 1){\n","    __syncthreads();\n","   //printf(\"i = %d \\t tx = %d \\t offset = %d \\n\",i,tx,stride);\n","    if(tx< stride){\n","        sdata[tx] += sdata[tx + stride];\n","    }\n","  }\n","  \n","  if(threadIdx.x == 0) \n","  { \n","    results[blockIdx.x] = sdata[0]; \n","  } \n","}\n","\n","__global__ void kernelReduceAvg(int *input, int *results, int n){\n","  __shared__ int sdata[BLOCK_SIZE]; \n","  int i = blockIdx.x * blockDim.x + threadIdx.x;\n","  int tx = threadIdx.x; \n","\n","  int temp = 0; \n","  if(i< n){\n","  temp = input[i]; \n","  sdata[tx] = temp; \n","  }\n","  __syncthreads();\n","\n","  for(int stride = blockDim.x>>1; stride > 0; stride >>= 1){\n","    __syncthreads();\n","   //printf(\"i = %d \\t tx = %d \\t offset = %d \\n\",i,tx,stride);\n","    if(tx< stride){\n","        sdata[tx] =(sdata[tx] + sdata[tx + stride])/2;\n","    }\n","\n","  }\n","  \n","  if(threadIdx.x == 0) \n","  {  \n","    results[blockIdx.x] = sdata[0]; \n","  } \n","}\n","\n","/*\n","void ReduceMin(){}\n","void ReduceMax(){}\n","void ReduceSum(){}\n","void ReduceAvg(){}\n","*/\n","\n","  int main(){ \n","      \n","  //1- Declare variables\n","\n","    int num_blocks = SOA / BLOCK_SIZE; //512/64\n","    int num_threads=BLOCK_SIZE,i;\n","    \n","    int mem_size_a = sizeof(int) * SOA;\n","    int mem_size_b = sizeof(int) * num_blocks;\n","    int mem_size_c = sizeof(int) ;\n","  \n","  //2- Allocate Memory to variables\n","\n","    int* h_a = (int*)malloc(sizeof(int) * SOA);\n","    int* h_b = (int*)malloc(sizeof(int) * num_blocks);\n","    int* h_c = (int*)malloc(sizeof(int));\n","\n","    int* d_a;\n","    cudaMalloc((void**) &d_a, sizeof(int) * SOA);\n","    int* d_b;\n","    cudaMalloc((void**) &d_b, sizeof(int) * num_blocks);\n","    int* d_c;\n","    cudaMalloc((void**) &d_c, sizeof(int));\n","\n","  //3-Fill host variables with data\n","\n","    randomInit(h_a,SOA);\n","\n","//MIN\n","    printf(\"REDUCE MIN:>\");\n","\n","  //4-Copy Data Host to device\n","\n","    cudaMemcpy(d_a, h_a, sizeof(int) * SOA, cudaMemcpyHostToDevice);\n","  \n","  //5-Call Kernel function\n","\n","    //reduce per-block partial mins\n","    kernelReduceMin<<<num_blocks, num_threads>>>(d_a,d_b,SOA);\n","    //then reduce partial mins to a final mix\n","    kernelReduceMin<<<1, num_blocks>>>(d_b,d_c,num_blocks);\n","    \n","  //6-Copy Data Device to Host\n","\n","    cudaMemcpy(h_b, d_b, mem_size_b, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_c, d_c, mem_size_c, cudaMemcpyDeviceToHost);\n","\n","  //7-Check results\n","\n","    printf(\"\\nh_a[]\\n\");\n","    for(i=0;i<SOA;i++){\n","      printf(\"%d\\t\",h_a[i]);\n","    }\n","    \n","    printf(\"\\nh_b[] \\n\");\n","    for(i=0;i<num_blocks;i++){\n","      printf(\"%d\\t\",h_b[i]);\n","    }printf(\"\\n\");\n","    \n","    printf(\"parallel min=%d\\n\",*h_c);\n","\n","//MAX\n","    printf(\"REDUCE MAX:>\");\n","    cudaMemcpy(d_a, h_a, sizeof(int) * SOA, cudaMemcpyHostToDevice);\n","\n","    kernelReduceMax<<<num_blocks, num_threads>>>(d_a,d_b,SOA);\n","    kernelReduceMax<<<1, num_blocks>>>(d_b,d_c,num_blocks);\n","    \n","    cudaMemcpy(h_b, d_b, mem_size_b, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_c, d_c, mem_size_c, cudaMemcpyDeviceToHost);\n","    \n","    printf(\"\\nh_a[]\\n\");\n","    for(i=0;i<SOA;i++){\n","      printf(\"%d\\t\",h_a[i]);\n","    }\n","    \n","    printf(\"\\nh_b[]\\n\");\n","    for(i=0;i<num_blocks;i++){\n","      printf(\"%d\\t\",h_b[i]);\n","    }printf(\"\\n\");\n","    \n","    printf(\"parallel max=%d\\n\",*h_c);\n","\n","//SUM\n","    printf(\"REDUCE SUM:>\");\n","    cudaMemcpy(d_a, h_a, sizeof(int) * SOA, cudaMemcpyHostToDevice);\n","\n","    kernelReduceSum<<<num_blocks, num_threads>>>(d_a,d_b,SOA);\n","    kernelReduceSum<<<1, num_blocks>>>(d_b,d_c,num_blocks);\n","    \n","    cudaMemcpy(h_b, d_b, mem_size_b, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_c, d_c, mem_size_c, cudaMemcpyDeviceToHost);\n","    \n","    printf(\"\\nh_a[]\\n\");\n","    for(i=0;i<SOA;i++){\n","      printf(\"%d\\t\",h_a[i]);\n","    }\n","    \n","    printf(\"\\nh_b[] \\n\");\n","    for(i=0;i<num_blocks;i++){\n","      printf(\"%d\\t\",h_b[i]);\n","    }printf(\"\\n\");\n","    \n","    printf(\"parallel Sum=%d\\n\",*h_c);\n","\n","//AVG\n","    printf(\"REDUCE AVG:>\");\n","    cudaMemcpy(d_a, h_a, sizeof(int) * SOA, cudaMemcpyHostToDevice);\n","\n","    //reduce per-block partial avg\n","    kernelReduceAvg<<<num_blocks, num_threads>>>(d_a,d_b,SOA);\n","    kernelReduceAvg<<<1, num_blocks>>>(d_b,d_c,num_blocks);\n","    \n","    cudaMemcpy(h_b, d_b, mem_size_b, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(h_c, d_c, mem_size_c, cudaMemcpyDeviceToHost);\n","    \n","    printf(\"\\nh_a[]\\n\");\n","    for(i=0;i<SOA;i++){\n","      printf(\"%d\\t\",h_a[i]);\n","    }\n","    \n","    printf(\"\\nh_b[] \\n\");\n","    for(i=0;i<num_blocks;i++){\n","      printf(\"%d\\t\",h_b[i]);\n","    }printf(\"\\n\");\n","    \n","    printf(\"parallel Avg=%d\\n\",*h_c);\n","\n","  //8-Deallocate Memory\n","\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","\n","    cudaThreadExit();\n","\n","  }"],"execution_count":null,"outputs":[{"output_type":"stream","text":["REDUCE MIN:>\n","h_a[]\n","0\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t120\t130\t140\t150\t160\t170\t180\t190\t200\t210\t220\t230\t240\t250\t260\t270\t280\t290\t300\t310\t320\t330\t340\t350\t360\t370\t380\t390\t400\t410\t420\t430\t440\t450\t460\t470\t480\t490\t500\t510\t520\t530\t540\t550\t560\t570\t580\t590\t600\t610\t620\t630\t640\t650\t660\t670\t680\t690\t700\t710\t720\t730\t740\t750\t760\t770\t780\t790\t800\t810\t820\t830\t840\t850\t860\t870\t880\t890\t900\t910\t920\t930\t940\t950\t960\t970\t980\t990\t1000\t1010\t1020\t1030\t1040\t1050\t1060\t1070\t1080\t1090\t1100\t1110\t1120\t1130\t1140\t1150\t1160\t1170\t1180\t1190\t1200\t1210\t1220\t1230\t1240\t1250\t1260\t1270\t1280\t1290\t1300\t1310\t1320\t1330\t1340\t1350\t1360\t1370\t1380\t1390\t1400\t1410\t1420\t1430\t1440\t1450\t1460\t1470\t1480\t1490\t1500\t1510\t1520\t1530\t1540\t1550\t1560\t1570\t1580\t1590\t1600\t1610\t1620\t1630\t1640\t1650\t1660\t1670\t1680\t1690\t1700\t1710\t1720\t1730\t1740\t1750\t1760\t1770\t1780\t1790\t1800\t1810\t1820\t1830\t1840\t1850\t1860\t1870\t1880\t1890\t1900\t1910\t1920\t1930\t1940\t1950\t1960\t1970\t1980\t1990\t2000\t2010\t2020\t2030\t2040\t2050\t2060\t2070\t2080\t2090\t2100\t2110\t2120\t2130\t2140\t2150\t2160\t2170\t2180\t2190\t2200\t2210\t2220\t2230\t2240\t2250\t2260\t2270\t2280\t2290\t2300\t2310\t2320\t2330\t2340\t2350\t2360\t2370\t2380\t2390\t2400\t2410\t2420\t2430\t2440\t2450\t2460\t2470\t2480\t2490\t2500\t2510\t2520\t2530\t2540\t2550\t2560\t2570\t2580\t2590\t2600\t2610\t2620\t2630\t2640\t2650\t2660\t2670\t2680\t2690\t2700\t2710\t2720\t2730\t2740\t2750\t2760\t2770\t2780\t2790\t2800\t2810\t2820\t2830\t2840\t2850\t2860\t2870\t2880\t2890\t2900\t2910\t2920\t2930\t2940\t2950\t2960\t2970\t2980\t2990\t3000\t3010\t3020\t3030\t3040\t3050\t3060\t3070\t3080\t3090\t3100\t3110\t3120\t3130\t3140\t3150\t3160\t3170\t3180\t3190\t3200\t3210\t3220\t3230\t3240\t3250\t3260\t3270\t3280\t3290\t3300\t3310\t3320\t3330\t3340\t3350\t3360\t3370\t3380\t3390\t3400\t3410\t3420\t3430\t3440\t3450\t3460\t3470\t3480\t3490\t3500\t3510\t3520\t3530\t3540\t3550\t3560\t3570\t3580\t3590\t3600\t3610\t3620\t3630\t3640\t3650\t3660\t3670\t3680\t3690\t3700\t3710\t3720\t3730\t3740\t3750\t3760\t3770\t3780\t3790\t3800\t3810\t3820\t3830\t3840\t3850\t3860\t3870\t3880\t3890\t3900\t3910\t3920\t3930\t3940\t3950\t3960\t3970\t3980\t3990\t4000\t4010\t4020\t4030\t4040\t4050\t4060\t4070\t4080\t4090\t4100\t4110\t4120\t4130\t4140\t4150\t4160\t4170\t4180\t4190\t4200\t4210\t4220\t4230\t4240\t4250\t4260\t4270\t4280\t4290\t4300\t4310\t4320\t4330\t4340\t4350\t4360\t4370\t4380\t4390\t4400\t4410\t4420\t4430\t4440\t4450\t4460\t4470\t4480\t4490\t4500\t4510\t4520\t4530\t4540\t4550\t4560\t4570\t4580\t4590\t4600\t4610\t4620\t4630\t4640\t4650\t4660\t4670\t4680\t4690\t4700\t4710\t4720\t4730\t4740\t4750\t4760\t4770\t4780\t4790\t4800\t4810\t4820\t4830\t4840\t4850\t4860\t4870\t4880\t4890\t4900\t4910\t4920\t4930\t4940\t4950\t4960\t4970\t4980\t4990\t5000\t5010\t5020\t5030\t5040\t5050\t5060\t5070\t5080\t5090\t5100\t5110\t\n","h_b[] \n","0\t640\t1280\t1920\t2560\t3200\t3840\t4480\t\n","parallel min=0\n","REDUCE MAX:>\n","h_a[]\n","0\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t120\t130\t140\t150\t160\t170\t180\t190\t200\t210\t220\t230\t240\t250\t260\t270\t280\t290\t300\t310\t320\t330\t340\t350\t360\t370\t380\t390\t400\t410\t420\t430\t440\t450\t460\t470\t480\t490\t500\t510\t520\t530\t540\t550\t560\t570\t580\t590\t600\t610\t620\t630\t640\t650\t660\t670\t680\t690\t700\t710\t720\t730\t740\t750\t760\t770\t780\t790\t800\t810\t820\t830\t840\t850\t860\t870\t880\t890\t900\t910\t920\t930\t940\t950\t960\t970\t980\t990\t1000\t1010\t1020\t1030\t1040\t1050\t1060\t1070\t1080\t1090\t1100\t1110\t1120\t1130\t1140\t1150\t1160\t1170\t1180\t1190\t1200\t1210\t1220\t1230\t1240\t1250\t1260\t1270\t1280\t1290\t1300\t1310\t1320\t1330\t1340\t1350\t1360\t1370\t1380\t1390\t1400\t1410\t1420\t1430\t1440\t1450\t1460\t1470\t1480\t1490\t1500\t1510\t1520\t1530\t1540\t1550\t1560\t1570\t1580\t1590\t1600\t1610\t1620\t1630\t1640\t1650\t1660\t1670\t1680\t1690\t1700\t1710\t1720\t1730\t1740\t1750\t1760\t1770\t1780\t1790\t1800\t1810\t1820\t1830\t1840\t1850\t1860\t1870\t1880\t1890\t1900\t1910\t1920\t1930\t1940\t1950\t1960\t1970\t1980\t1990\t2000\t2010\t2020\t2030\t2040\t2050\t2060\t2070\t2080\t2090\t2100\t2110\t2120\t2130\t2140\t2150\t2160\t2170\t2180\t2190\t2200\t2210\t2220\t2230\t2240\t2250\t2260\t2270\t2280\t2290\t2300\t2310\t2320\t2330\t2340\t2350\t2360\t2370\t2380\t2390\t2400\t2410\t2420\t2430\t2440\t2450\t2460\t2470\t2480\t2490\t2500\t2510\t2520\t2530\t2540\t2550\t2560\t2570\t2580\t2590\t2600\t2610\t2620\t2630\t2640\t2650\t2660\t2670\t2680\t2690\t2700\t2710\t2720\t2730\t2740\t2750\t2760\t2770\t2780\t2790\t2800\t2810\t2820\t2830\t2840\t2850\t2860\t2870\t2880\t2890\t2900\t2910\t2920\t2930\t2940\t2950\t2960\t2970\t2980\t2990\t3000\t3010\t3020\t3030\t3040\t3050\t3060\t3070\t3080\t3090\t3100\t3110\t3120\t3130\t3140\t3150\t3160\t3170\t3180\t3190\t3200\t3210\t3220\t3230\t3240\t3250\t3260\t3270\t3280\t3290\t3300\t3310\t3320\t3330\t3340\t3350\t3360\t3370\t3380\t3390\t3400\t3410\t3420\t3430\t3440\t3450\t3460\t3470\t3480\t3490\t3500\t3510\t3520\t3530\t3540\t3550\t3560\t3570\t3580\t3590\t3600\t3610\t3620\t3630\t3640\t3650\t3660\t3670\t3680\t3690\t3700\t3710\t3720\t3730\t3740\t3750\t3760\t3770\t3780\t3790\t3800\t3810\t3820\t3830\t3840\t3850\t3860\t3870\t3880\t3890\t3900\t3910\t3920\t3930\t3940\t3950\t3960\t3970\t3980\t3990\t4000\t4010\t4020\t4030\t4040\t4050\t4060\t4070\t4080\t4090\t4100\t4110\t4120\t4130\t4140\t4150\t4160\t4170\t4180\t4190\t4200\t4210\t4220\t4230\t4240\t4250\t4260\t4270\t4280\t4290\t4300\t4310\t4320\t4330\t4340\t4350\t4360\t4370\t4380\t4390\t4400\t4410\t4420\t4430\t4440\t4450\t4460\t4470\t4480\t4490\t4500\t4510\t4520\t4530\t4540\t4550\t4560\t4570\t4580\t4590\t4600\t4610\t4620\t4630\t4640\t4650\t4660\t4670\t4680\t4690\t4700\t4710\t4720\t4730\t4740\t4750\t4760\t4770\t4780\t4790\t4800\t4810\t4820\t4830\t4840\t4850\t4860\t4870\t4880\t4890\t4900\t4910\t4920\t4930\t4940\t4950\t4960\t4970\t4980\t4990\t5000\t5010\t5020\t5030\t5040\t5050\t5060\t5070\t5080\t5090\t5100\t5110\t\n","h_b[]\n","630\t1270\t1910\t2550\t3190\t3830\t4470\t5110\t\n","parallel max=5110\n","REDUCE SUM:>\n","h_a[]\n","0\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t120\t130\t140\t150\t160\t170\t180\t190\t200\t210\t220\t230\t240\t250\t260\t270\t280\t290\t300\t310\t320\t330\t340\t350\t360\t370\t380\t390\t400\t410\t420\t430\t440\t450\t460\t470\t480\t490\t500\t510\t520\t530\t540\t550\t560\t570\t580\t590\t600\t610\t620\t630\t640\t650\t660\t670\t680\t690\t700\t710\t720\t730\t740\t750\t760\t770\t780\t790\t800\t810\t820\t830\t840\t850\t860\t870\t880\t890\t900\t910\t920\t930\t940\t950\t960\t970\t980\t990\t1000\t1010\t1020\t1030\t1040\t1050\t1060\t1070\t1080\t1090\t1100\t1110\t1120\t1130\t1140\t1150\t1160\t1170\t1180\t1190\t1200\t1210\t1220\t1230\t1240\t1250\t1260\t1270\t1280\t1290\t1300\t1310\t1320\t1330\t1340\t1350\t1360\t1370\t1380\t1390\t1400\t1410\t1420\t1430\t1440\t1450\t1460\t1470\t1480\t1490\t1500\t1510\t1520\t1530\t1540\t1550\t1560\t1570\t1580\t1590\t1600\t1610\t1620\t1630\t1640\t1650\t1660\t1670\t1680\t1690\t1700\t1710\t1720\t1730\t1740\t1750\t1760\t1770\t1780\t1790\t1800\t1810\t1820\t1830\t1840\t1850\t1860\t1870\t1880\t1890\t1900\t1910\t1920\t1930\t1940\t1950\t1960\t1970\t1980\t1990\t2000\t2010\t2020\t2030\t2040\t2050\t2060\t2070\t2080\t2090\t2100\t2110\t2120\t2130\t2140\t2150\t2160\t2170\t2180\t2190\t2200\t2210\t2220\t2230\t2240\t2250\t2260\t2270\t2280\t2290\t2300\t2310\t2320\t2330\t2340\t2350\t2360\t2370\t2380\t2390\t2400\t2410\t2420\t2430\t2440\t2450\t2460\t2470\t2480\t2490\t2500\t2510\t2520\t2530\t2540\t2550\t2560\t2570\t2580\t2590\t2600\t2610\t2620\t2630\t2640\t2650\t2660\t2670\t2680\t2690\t2700\t2710\t2720\t2730\t2740\t2750\t2760\t2770\t2780\t2790\t2800\t2810\t2820\t2830\t2840\t2850\t2860\t2870\t2880\t2890\t2900\t2910\t2920\t2930\t2940\t2950\t2960\t2970\t2980\t2990\t3000\t3010\t3020\t3030\t3040\t3050\t3060\t3070\t3080\t3090\t3100\t3110\t3120\t3130\t3140\t3150\t3160\t3170\t3180\t3190\t3200\t3210\t3220\t3230\t3240\t3250\t3260\t3270\t3280\t3290\t3300\t3310\t3320\t3330\t3340\t3350\t3360\t3370\t3380\t3390\t3400\t3410\t3420\t3430\t3440\t3450\t3460\t3470\t3480\t3490\t3500\t3510\t3520\t3530\t3540\t3550\t3560\t3570\t3580\t3590\t3600\t3610\t3620\t3630\t3640\t3650\t3660\t3670\t3680\t3690\t3700\t3710\t3720\t3730\t3740\t3750\t3760\t3770\t3780\t3790\t3800\t3810\t3820\t3830\t3840\t3850\t3860\t3870\t3880\t3890\t3900\t3910\t3920\t3930\t3940\t3950\t3960\t3970\t3980\t3990\t4000\t4010\t4020\t4030\t4040\t4050\t4060\t4070\t4080\t4090\t4100\t4110\t4120\t4130\t4140\t4150\t4160\t4170\t4180\t4190\t4200\t4210\t4220\t4230\t4240\t4250\t4260\t4270\t4280\t4290\t4300\t4310\t4320\t4330\t4340\t4350\t4360\t4370\t4380\t4390\t4400\t4410\t4420\t4430\t4440\t4450\t4460\t4470\t4480\t4490\t4500\t4510\t4520\t4530\t4540\t4550\t4560\t4570\t4580\t4590\t4600\t4610\t4620\t4630\t4640\t4650\t4660\t4670\t4680\t4690\t4700\t4710\t4720\t4730\t4740\t4750\t4760\t4770\t4780\t4790\t4800\t4810\t4820\t4830\t4840\t4850\t4860\t4870\t4880\t4890\t4900\t4910\t4920\t4930\t4940\t4950\t4960\t4970\t4980\t4990\t5000\t5010\t5020\t5030\t5040\t5050\t5060\t5070\t5080\t5090\t5100\t5110\t\n","h_b[] \n","20160\t61120\t102080\t143040\t184000\t224960\t265920\t306880\t\n","parallel Sum=1308160\n","REDUCE AVG:>\n","h_a[]\n","0\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t120\t130\t140\t150\t160\t170\t180\t190\t200\t210\t220\t230\t240\t250\t260\t270\t280\t290\t300\t310\t320\t330\t340\t350\t360\t370\t380\t390\t400\t410\t420\t430\t440\t450\t460\t470\t480\t490\t500\t510\t520\t530\t540\t550\t560\t570\t580\t590\t600\t610\t620\t630\t640\t650\t660\t670\t680\t690\t700\t710\t720\t730\t740\t750\t760\t770\t780\t790\t800\t810\t820\t830\t840\t850\t860\t870\t880\t890\t900\t910\t920\t930\t940\t950\t960\t970\t980\t990\t1000\t1010\t1020\t1030\t1040\t1050\t1060\t1070\t1080\t1090\t1100\t1110\t1120\t1130\t1140\t1150\t1160\t1170\t1180\t1190\t1200\t1210\t1220\t1230\t1240\t1250\t1260\t1270\t1280\t1290\t1300\t1310\t1320\t1330\t1340\t1350\t1360\t1370\t1380\t1390\t1400\t1410\t1420\t1430\t1440\t1450\t1460\t1470\t1480\t1490\t1500\t1510\t1520\t1530\t1540\t1550\t1560\t1570\t1580\t1590\t1600\t1610\t1620\t1630\t1640\t1650\t1660\t1670\t1680\t1690\t1700\t1710\t1720\t1730\t1740\t1750\t1760\t1770\t1780\t1790\t1800\t1810\t1820\t1830\t1840\t1850\t1860\t1870\t1880\t1890\t1900\t1910\t1920\t1930\t1940\t1950\t1960\t1970\t1980\t1990\t2000\t2010\t2020\t2030\t2040\t2050\t2060\t2070\t2080\t2090\t2100\t2110\t2120\t2130\t2140\t2150\t2160\t2170\t2180\t2190\t2200\t2210\t2220\t2230\t2240\t2250\t2260\t2270\t2280\t2290\t2300\t2310\t2320\t2330\t2340\t2350\t2360\t2370\t2380\t2390\t2400\t2410\t2420\t2430\t2440\t2450\t2460\t2470\t2480\t2490\t2500\t2510\t2520\t2530\t2540\t2550\t2560\t2570\t2580\t2590\t2600\t2610\t2620\t2630\t2640\t2650\t2660\t2670\t2680\t2690\t2700\t2710\t2720\t2730\t2740\t2750\t2760\t2770\t2780\t2790\t2800\t2810\t2820\t2830\t2840\t2850\t2860\t2870\t2880\t2890\t2900\t2910\t2920\t2930\t2940\t2950\t2960\t2970\t2980\t2990\t3000\t3010\t3020\t3030\t3040\t3050\t3060\t3070\t3080\t3090\t3100\t3110\t3120\t3130\t3140\t3150\t3160\t3170\t3180\t3190\t3200\t3210\t3220\t3230\t3240\t3250\t3260\t3270\t3280\t3290\t3300\t3310\t3320\t3330\t3340\t3350\t3360\t3370\t3380\t3390\t3400\t3410\t3420\t3430\t3440\t3450\t3460\t3470\t3480\t3490\t3500\t3510\t3520\t3530\t3540\t3550\t3560\t3570\t3580\t3590\t3600\t3610\t3620\t3630\t3640\t3650\t3660\t3670\t3680\t3690\t3700\t3710\t3720\t3730\t3740\t3750\t3760\t3770\t3780\t3790\t3800\t3810\t3820\t3830\t3840\t3850\t3860\t3870\t3880\t3890\t3900\t3910\t3920\t3930\t3940\t3950\t3960\t3970\t3980\t3990\t4000\t4010\t4020\t4030\t4040\t4050\t4060\t4070\t4080\t4090\t4100\t4110\t4120\t4130\t4140\t4150\t4160\t4170\t4180\t4190\t4200\t4210\t4220\t4230\t4240\t4250\t4260\t4270\t4280\t4290\t4300\t4310\t4320\t4330\t4340\t4350\t4360\t4370\t4380\t4390\t4400\t4410\t4420\t4430\t4440\t4450\t4460\t4470\t4480\t4490\t4500\t4510\t4520\t4530\t4540\t4550\t4560\t4570\t4580\t4590\t4600\t4610\t4620\t4630\t4640\t4650\t4660\t4670\t4680\t4690\t4700\t4710\t4720\t4730\t4740\t4750\t4760\t4770\t4780\t4790\t4800\t4810\t4820\t4830\t4840\t4850\t4860\t4870\t4880\t4890\t4900\t4910\t4920\t4930\t4940\t4950\t4960\t4970\t4980\t4990\t5000\t5010\t5020\t5030\t5040\t5050\t5060\t5070\t5080\t5090\t5100\t5110\t\n","h_b[] \n","315\t955\t1595\t2235\t2875\t3515\t4155\t4795\t\n","parallel Avg=2555\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ptSvov5IQSLI"},"source":["b)Write CUDA programs that, given an N-element vector, find \n","1. The maximum element in the vector.\n","2. The minimum element in the vector.\n","3. The arithmetic mean of the vector.\n","4. The standard deviation of the values in the vector.\n","\n","Test for input N and generate a randomized vector V of length N (N should be large). The program should generate output as the two computed maximum values as well as the time taken to find each value.\n","\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JofBDupXQZcw","outputId":"31d38739-c372-4fa2-cc42-089a6fa2c822"},"source":["%%cu\n","#include<iostream>\n","#include<cstdio>\n","\n","using namespace std;\n","\n","__global__ void maximum(int *a,int *b,int n){\n","\tint block=256*blockIdx.x; \n","\tint max=0;\n","\n","\tfor(int i=block;i<min(256+block,n);i++){\n","\t\tif(max<a[i]){\n","\t\t\tmax=a[i];\t\n","\t\t}\n","\t}\n","\tb[blockIdx.x]=max;\n","}\n","\n","__global__ void minimum(int *a,int *b,int n){\n","\tint block=256*blockIdx.x;\n","\tint mini=7888888;\n","\n","\tfor(int i=block;i<min(256+block,n);i++){\n","\t\tif(mini>a[i]){\n","\t\t\tmini=a[i];\n","\t\t}\n","\t}\n","\tb[blockIdx.x]=mini;\n","}\n","\n","__global__ void sum(int *a,int *b,int n){\n","\tint block=256*blockIdx.x;\n","\tint sum=0;\n","\n","\tfor(int i=block;i<min(block+256,n);i++){\n","\t\tsum=sum+a[i];\n","\t}\n","\tb[blockIdx.x]=sum;\n","}\n","\n","__global__ void var(int *a,int *b,int n,float mean){\n","\tint block=256*blockIdx.x;\n","\tfloat sum=0;\n","\n","\tfor(int i=block;i<min(block+256,n);i++){\n","\t  sum=sum+(a[i]-mean)*(a[i]-mean);\n","\t}\n","\tb[blockIdx.x]=sum;\n","}\n","\n","void maxInVector(){\n","\tint n = 512;\n","\tint a[n];\n","\tcudaEvent_t start,end;\n","\n","\tfor(int i=0;i<n;i++){\n","\t\ta[i]=i+1;\n","\t}\n","\n","\tint *ad,*bd;\n","\tint size=n*sizeof(int);\n","\t\n","\tcudaMalloc(&ad,size);\n","\tcudaMemcpy(ad,a,size,cudaMemcpyHostToDevice);\n","\n","\tint grids=ceil(n*1.0f/256.0f);\n","\tcudaMalloc(&bd,grids*sizeof(int));\n","\n","\tdim3 grid(grids,1);\n","\tdim3 block(1,1);\n","\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&end);\n","\tcudaEventRecord(start);\n","\n","\twhile(n>1){\n","\t\tmaximum<<<grids,block>>>(ad,bd,n);\n","\t\tn=ceil(n*1.0f/256.0f);\n","\t\tcudaMemcpy(ad,bd,n*sizeof(int),cudaMemcpyDeviceToDevice);\n","\t}\n","\n","\tcudaEventRecord(end);\n","\tcudaEventSynchronize(end);\n","\n","\tfloat time=0;\n","\tcudaEventElapsedTime(&time,start,end);\t\n","\tint ans[2];\n","\tcudaMemcpy(ans,ad,4,cudaMemcpyDeviceToHost);\n","\t\n","\tcout<<\"The maximum element is \"<<ans[0]<<endl;\t\n","\tcout<<\"The time required do it is \";\n","\tcout<<time<<endl;\n","\n","}\n","\n","void minInVector(){\n","  int n = 512;\n","\tint a[n];\n","\n","\tcudaEvent_t start,end;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&end);\n","\n","\tfor(int i=0;i<n;i++){\n","\t\ta[i]=i+1;\n","\t}\n","\t\n","\tint *ad,*bd;\n","\tint size=n*sizeof(int);\n","\t\n","\tcudaMalloc(&ad,size);\n","\tcudaMemcpy(ad,a,size,cudaMemcpyHostToDevice);\n","\n","  int grids=ceil(n*1.0f/256.0f);\n","\tcudaMalloc(&bd,grids*sizeof(int));\n","\n","\tdim3 grid(grids,1);\n","\tdim3 block(1,1);\n","\tcudaEventRecord(start);\n","\twhile(n>1){\n","\t\tminimum<<<grids,block>>>(ad,bd,n);\n","\t\tn=ceil(n*1.0f/256.0f);\n","\t\tcudaMemcpy(ad,bd,n*sizeof(int),cudaMemcpyDeviceToDevice);\n","\t}\n","\n","\tcudaEventRecord(end);\n","\tcudaEventSynchronize(end);\n","\tfloat time=0;\n","\tcudaEventElapsedTime(&time,start,end);\n","\n","\tint ans[2];\n","\tcudaMemcpy(ans,ad,4,cudaMemcpyDeviceToHost);\n","\t\n","\tcout<<\"The minimum element is \"<<ans[0]<<endl;\n","\t\n","\tcout<<\"The time required dor it is \";\n","\tcout<<time<<endl;\n","}\n","\n","void meanInVector(){\n","  int n = 512;\n","\tint a[n];\n","\tfor(int i=0;i<n;i++){\n","\t\ta[i]=i+1;\n","\t}\n","\n","\tint *ad,*bd;\n","\tint size=n*sizeof(int);\n","\n","\tcudaMalloc(&ad,size);\n","\tcudaMemcpy(ad,a,size,cudaMemcpyHostToDevice);\n","\n","\tint grids=ceil(n*1.0f/256.0f);\n","\tcudaMalloc(&bd,grids*sizeof(int));\n","\n","\tdim3 grid(grids,1);\n","\tdim3 block(1,1);\n","\tint p=n;\n","\n","\tcudaEvent_t start,end;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&end);\n","\tcudaEventRecord(start);\n","\n","\twhile(n>1){\n","\t\tsum<<<grid,block>>>(ad,bd,n);\n","\t\tn=ceil(n*1.0f/256.0f);\n","\t\tcudaMemcpy(ad,bd,n*sizeof(int),cudaMemcpyDeviceToDevice);\n","\t}\n","\n","\tcudaEventRecord(end);\n","\tcudaEventSynchronize(end);\n","\n","  float time=0;\n","\tcudaEventElapsedTime(&time,start,end);\n","  cout<<\"The time required is \"<<time<<endl;\n","\n","\tint add[2];\n","\tn=p;\n","\n","\tcudaMemcpy(add,ad,4,cudaMemcpyDeviceToHost);\n","\tcout<<\"The sum is  \"<<add[0]<<endl;\n","\n","\tfloat mean=0.0f;\n","\tmean=add[0]/(n*1.0f);\n","\tcout<<\"The mean is   \"<<mean<<endl;\n","}\n","\n","void sdInVector(){\n","  int n = 512;\n","\tint a[n];\n","\n","\tfor(int i=0;i<n;i++){\n","\t  a[i]=i+1;\n","\t}\n","\n","\tint *ad,*bd;\n","\tint size=n*sizeof(int);\n","\n","\tcudaMalloc(&ad,size);\n","\tcudaMemcpy(ad,a,size,cudaMemcpyHostToDevice);\n","\n","\tint grids=ceil(n*1.0f/256.0f);\n","\tcudaMalloc(&bd,grids*sizeof(int));\n","\n","\tdim3 grid(grids,1);\n","\tdim3 block(1,1);\n","\n","\tint p=n;\n","\n","\tcudaEvent_t start,end;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&end);\n","\tcudaEventRecord(start);\n","\n","\twhile(n>1){\n","\t\tsum<<<grid,block>>>(ad,bd,n);\n","\t\tn=ceil(n*1.0f/256.0f);\n","\t\tcudaMemcpy(ad,bd,n*sizeof(int),cudaMemcpyDeviceToDevice);\n","\t}\n","\n","\tcudaEventRecord(end);\n","\tcudaEventSynchronize(end);\n","\n","\tfloat time=0;\n","\tcudaEventElapsedTime(&time,start,end);\n","\tcout<<\"The time required is \"<<time<<endl;\n","\n","\tint add[2];\n","\tn=p;\n","\n","\tcudaMemcpy(add,ad,4,cudaMemcpyDeviceToHost);\n","\tcout<<\"The sum is  \"<<add[0]<<endl;\n","\n","\tfloat mean=0.0f;\n","\tmean=add[0]/(n*1.0f);\n","\n","\tcout<<\"The mean is   \"<<mean<<endl;\n","\tcudaMalloc(&ad,size);\n","\tcudaMemcpy(ad,a,size,cudaMemcpyHostToDevice);\n","\tcudaMalloc(&bd,grids*sizeof(int));\n","\n","\tvar<<<grid,block>>>(ad,bd,n,mean);\n","\tn=ceil(n*1.0f/256.0f);\t\n","\n","\tsum<<<grid,block>>>(bd,ad,n);\n","\n","\tcudaMemcpy(add,ad,4,cudaMemcpyDeviceToHost);\n","\n","\tfloat sd=sqrt(add[0]/p*1.0f);\n","\tcout<<\"The standard deviation is \"<<sd<<endl;\n","}\n","\n","int main(){\n","    cout<<\"The maximum element in the vector.\"<<endl;\n","    maxInVector();\n","    cout<<endl<<endl<<endl<<\"The minimum element in the vector.\"<<endl;\n","    minInVector();\n","    cout<<endl<<endl<<endl<<\"The arithmetic mean of the vector.\"<<endl;\n","    meanInVector();\n","    cout<<endl<<endl<<endl<<\"The standard deviation of the values in the vector.\"<<endl;    \n","    sdInVector();\n","} \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The maximum element in the vector.\n","The maximum element is 512\n","The time required do it is 0.037184\n","\n","\n","\n","The minimum element in the vector.\n","The minimum element is 1\n","The time required dor it is 0.026656\n","\n","\n","\n","The arithmetic mean of the vector.\n","The time required is 0.032352\n","The sum is  131328\n","The mean is   256.5\n","\n","\n","\n","The standard deviation of the values in the vector.\n","The time required is 0.025152\n","The sum is  131328\n","The mean is   256.5\n","The standard deviation is 147.801\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VCvZvVru2cLT"},"source":["# Average"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_t1Q9v82B-2","executionInfo":{"status":"ok","timestamp":1619267205330,"user_tz":-330,"elapsed":1599,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"13f88f50-4ba4-411e-f93a-f45d2d6f7dc7"},"source":["%%cu\n","#include<stdio.h>\n","#include<time.h>\n","\n","#define SIZE 100\n","\n","__global__ void sum(const int* __restrict__ input, const int size, int* sumOut)\n","{\n","    int i = threadIdx.x + blockDim.x * blockIdx.x;\n","    atomicAdd(sumOut, input[i]);\n","    __syncthreads();\n","}\n","\n","int main()\n","{\n","  int i;\n","  int a[SIZE];\n","  int c = 0;\n","  int *dev_a, *dev_c;\n","  float gpu_elapsed_time,avg;\n","  cudaEvent_t gpu_start,gpu_stop;\n","    \n","  cudaMalloc((void **) &dev_a, SIZE*sizeof(int));\n","  cudaMalloc((void **) &dev_c, sizeof(int));\n","  srand(time(0));\n","  for( i = 0 ; i < SIZE ; i++)\n","  {\n","    a[i] = (rand() % (1000 - 100 + 1)) + 100;\n","  }\n","  for( i = 0 ; i < SIZE ; i++)\n","  {\n","    printf(\"%d \",a[i]);\n","    if (i%10==0 && i!=0){\n","      printf(\"\\n\");\n","    }\n","  }\n","  cudaMemcpy(dev_c , &c, sizeof(int),cudaMemcpyHostToDevice);\n","  cudaMemcpy(dev_a , a, SIZE*sizeof(int),cudaMemcpyHostToDevice);\n","  cudaEventCreate(&gpu_start);\n","  cudaEventCreate(&gpu_stop);\n","  cudaEventRecord(gpu_start,0);\n","  sum<<<2,SIZE/2>>>(dev_a,SIZE,dev_c);\n","  cudaDeviceSynchronize();\n","  cudaMemcpy(&c, dev_c, sizeof(int),cudaMemcpyDeviceToHost);\n","  c = c / SIZE;\n","  cudaEventRecord(gpu_stop, 0);\n","  cudaEventSynchronize(gpu_stop);\n","  cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n","  cudaEventDestroy(gpu_start);\n","  cudaEventDestroy(gpu_stop);\n","  printf(\"avg =  %d \",c);\n","  printf(\"\\nThe gpu took: %f milli-seconds.\\n\",gpu_elapsed_time);\n","    \n","  printf(\"\\n\");\n","  printf(\"avg =  %d \",c);\n","  cudaFree(dev_a);\n","  cudaFree(dev_c);\n","  return 0;\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["876 236 113 995 244 500 371 600 343 364 884 \n","944 502 733 590 728 589 783 786 399 357 \n","572 208 202 767 393 268 969 677 788 142 \n","552 320 452 843 465 249 511 361 492 775 \n","541 435 574 273 321 598 158 103 384 458 \n","657 252 566 759 919 256 927 887 229 110 \n","325 978 331 677 821 993 826 331 650 614 \n","402 191 345 876 661 566 474 720 866 154 \n","474 522 306 940 577 521 492 800 407 621 \n","811 632 599 438 605 716 430 728 343 avg =  541 \n","The gpu took: 0.047744 milli-seconds.\n","\n","avg =  541 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xiRB6X1G2n00"},"source":["# Max"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJwp8X8V2SjV","executionInfo":{"status":"ok","timestamp":1619267343159,"user_tz":-330,"elapsed":1920,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"d0b3e558-9ad3-4391-c9a1-a52399fe4266"},"source":["%%cu\n","#include <stdio.h>\n","#include <time.h>\n","#define SIZE 100\n","\n","__global__ void max(const int* __restrict__ input, const int size, int* maxOut)\n","{\n","    int localMax = 0;\n","\n","    for (int i = threadIdx.x; i < size; i += blockDim.x)\n","    {\n","        int val = input[i];\n","        if (localMax < abs(val))\n","        {\n","            localMax = abs(val);\n","        }\n","    }\n","    atomicMax(maxOut, localMax);\n","    __syncthreads();\n","}\n","\n","int main()\n","{\n","  int i;\n","  int a[SIZE];\n","  int c;\n","  int *dev_a, *dev_c;\n","  cudaMalloc((void **) &dev_a, SIZE*sizeof(int));\n","  cudaMalloc((void **) &dev_c, sizeof(int));\n","  srand(time(0));\n","  for( i = 0 ; i < SIZE ; i++)\n","  {\n","    a[i] = rand()% 1000;\n","  }\n","  for( i = 0 ; i < SIZE ; i++)\n","  {\n","    printf(\"%d \",a[i]);\n","    if (i%10==0 && i!=0){\n","      printf(\"\\n\");\n","    }\n","  }\n","  c = a[0];\n","  cudaMemcpy(dev_c , &c, sizeof(int),cudaMemcpyHostToDevice);\n","  cudaMemcpy(dev_a , a, SIZE*sizeof(int),cudaMemcpyHostToDevice);\n","  max<<<2,SIZE/2>>>(dev_a,SIZE,dev_c);\n","  cudaDeviceSynchronize();\n","  cudaMemcpy(&c, dev_c, sizeof(int),cudaMemcpyDeviceToHost);\n","  printf(\"\\n\");\n","  printf(\"max =  %d \",c);\n","  cudaFree(dev_a);\n","  cudaFree(dev_c);\n","  return 0;\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["432 159 104 450 952 409 798 702 467 999 670 \n","635 243 791 93 478 967 757 752 267 190 \n","959 189 664 129 826 84 415 633 618 197 \n","65 778 653 868 730 63 18 784 530 369 \n","807 517 613 598 610 443 917 368 548 184 \n","910 507 725 574 636 551 10 404 536 628 \n","953 602 406 606 822 489 669 840 625 551 \n","209 432 68 174 30 31 970 299 751 518 \n","483 13 377 209 587 365 112 949 121 649 \n","577 74 603 336 681 425 177 702 617 \n","max =  999 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X2NB7c8j23p5"},"source":["# Min"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDeQwDur2uLt","executionInfo":{"status":"ok","timestamp":1619267401771,"user_tz":-330,"elapsed":2143,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"66755e14-a629-4768-ddfe-3e85a2cf5f8e"},"source":["%%cu\n","#include <stdio.h>\n","#include <time.h>\n","#define SIZE 100\n","\n","__global__ void min(const int* __restrict__ input, const int size, int* minOut)\n","{\n","    int localMin = 1000;\n","\n","    for (int i = threadIdx.x; i < size; i += blockDim.x)\n","    {\n","        int val = input[i];\n","        if (localMin > abs(val))\n","        {\n","            localMin = abs(val);\n","        }\n","    }\n","    atomicMin(minOut, localMin);\n","    __syncthreads();\n","}\n","\n","int main()\n","{\n","  int i;\n","  int a[SIZE];\n","  int c;\n","  int *dev_a, *dev_c;\n","  cudaMalloc((void **) &dev_a, SIZE*sizeof(int));\n","  cudaMalloc((void **) &dev_c, sizeof(int));\n","  srand(time(0));\n","  for( i = 0 ; i < SIZE ; i++)\n","  {\n","    a[i] = (rand() % (1000 - 100 + 1)) + 100;\n","  }\n","  for( i = 0 ; i < SIZE ; i++)\n","  {\n","    printf(\"%d \",a[i]);\n","    if (i%10==0 && i!=0){\n","      printf(\"\\n\");\n","    }\n","  }\n","  c = a[0];\n","  cudaMemcpy(dev_c , &c, sizeof(int),cudaMemcpyHostToDevice);\n","  cudaMemcpy(dev_a , a, SIZE*sizeof(int),cudaMemcpyHostToDevice);\n","  min<<<2,SIZE/2>>>(dev_a,SIZE,dev_c);\n","  cudaDeviceSynchronize();\n","  cudaMemcpy(&c, dev_c, sizeof(int),cudaMemcpyDeviceToHost);\n","  printf(\"\\n\");\n","  printf(\"min =  %d \",c);\n","  cudaFree(dev_a);\n","  cudaFree(dev_c);\n","  return 0;\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["615 214 374 155 823 863 752 457 401 863 344 \n","443 553 351 169 875 723 802 559 400 840 \n","925 570 443 115 471 360 243 748 191 146 \n","362 306 718 418 128 580 466 782 881 328 \n","423 620 178 674 986 953 693 183 511 994 \n","319 732 860 663 747 331 319 286 375 411 \n","630 638 617 347 956 942 827 421 723 103 \n","946 145 920 420 115 905 372 709 384 179 \n","702 604 207 561 563 250 188 782 437 464 \n","192 967 101 105 313 353 947 436 971 \n","min =  101 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NmMmjSs03FsL"},"source":["# Sum"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBCdWvUq3C0-","executionInfo":{"status":"ok","timestamp":1619267497380,"user_tz":-330,"elapsed":1592,"user":{"displayName":"Rasika Dhande","photoUrl":"","userId":"12292236381114877579"}},"outputId":"259d2431-7e4e-4054-b9f9-75a663e8d36d"},"source":["%%cu\n","#include<stdio.h>\n","\n","__global__ void sum(int* input, int* sumOut) {\n","        int i = threadIdx.x + blockIdx.x * blockDim.x;\n","        for(int j = 0; j < 100/(blockDim.x*gridDim.x); j++){\n","                if (i < 100){\n","                        atomicAdd(sumOut, input[i+(j*blockDim.x*gridDim.x)]);\n","                      //  printf(\"NUM:%d Thread: %d ||\\n\",input[i+(j*blockDim.x*gridDim.x)],i);\n","                }\n","        }\n","        __syncthreads();\n","}\n","\n","int main() {\n","        int n = 100;\n","        int input[n];\n","        int sumO = 0;\n","        int i = 0;\n","        for(i = 0; i < n; i++){\n","                input[i] = (rand() % 1000) + 100;\n","                /*if(i % 10 == 0){\n","                        printf(\"\\n\");\n","                }\n","                printf(\"%d \",input[i]);*/\n","        }\n","        \n","        int* d_input;\n","        int* d_sum;\n","        \n","        cudaMalloc((void**)&d_input, n * sizeof(int));\n","        cudaMalloc((void**)&d_sum, sizeof(int));\n","        \n","        cudaMemcpy(d_input, &input, n * sizeof(int), cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_sum, &sumO, sizeof(int), cudaMemcpyHostToDevice);\n","        \n","        sum<<<2,10>>>(d_input, d_sum);\n","        \n","        cudaMemcpy(&sumO, d_sum, sizeof(int), cudaMemcpyDeviceToHost);\n","        \n","        printf(\"\\nSum: %d\",sumO);\n","        \n","        cudaFree(d_sum);\n","        cudaFree(d_input);\n","        \n","        return 0;\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Sum: 57684\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2TqRmfMcQrzD"},"source":["# **Assignment 2**\n","\n","Vector and Matrix Operations :\n","\n","Design parallel algorithm to\n","1. Add two large vectors\n","2. Multiply Vector and Matrix\n","3. Multiply two N × N arrays using n2 processors.\n","\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64fBml66YNlJ","outputId":"96a4db57-ec09-4320-eab0-19af22316d2e"},"source":["%%cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <math.h>\n","#include <cuda.h>\n","#define N 4\n","#define TPB 2\n"," \n","// CUDA kernel. Each thread takes care of one element of c\n","__global__ void vecAdd(double *a, double *b, double *c, int n){\n","    // Get our global thread ID\n","    int id = blockIdx.x*blockDim.x+threadIdx.x; \n","    // Make sure we do not go out of bounds\n","    if (id < n)\n","        c[id] = a[id] + b[id];\n","}\n","\n","__global__ void matrixMultiplication(int *a, int *b, int *c, int n){\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    int sum = 0;\n","    int i;\n","    if (row < n && col < n){\n","      for( i=0; i<n ;i++){\n","        sum += a[row *n +i] *  b[i * n+ col];\n","      }\n","      c[row *N +col]=sum;\n","    }\n","}\n"," \n","void vecAdd(){\n","    // Size of vectors\n","    int n = 100000;\n"," \n","    // Host input vectors\n","    double *h_a;\n","    double *h_b;\n","    //Host output vector\n","    double *h_c;\n"," \n","    // Device input vectors\n","    double *d_a;\n","    double *d_b;\n","    //Device output vector\n","    double *d_c;\n"," \n","    // Size, in bytes, of each vector\n","    size_t bytes = n*sizeof(double);\n"," \n","    // Allocate memory for each vector on host\n","    h_a = (double*)malloc(bytes);\n","    h_b = (double*)malloc(bytes);\n","    h_c = (double*)malloc(bytes);\n"," \n","    // Allocate memory for each vector on GPU\n","    cudaMalloc(&d_a, bytes);\n","    cudaMalloc(&d_b, bytes);\n","    cudaMalloc(&d_c, bytes);\n"," \n","    int i;\n","    // Initialize vectors on host\n","    for( i = 0; i < n; i++ ){\n","        h_a[i] = i;\n","        h_b[i] = i;\n","    }\n"," \n","    // Copy host vectors to device\n","    cudaMemcpy( d_a, h_a, bytes, cudaMemcpyHostToDevice);\n","    cudaMemcpy( d_b, h_b, bytes, cudaMemcpyHostToDevice);\n"," \n","    int blockSize, gridSize;\n"," \n","    // Number of threads in each thread block\n","    blockSize = 1024;\n"," \n","    // Number of thread blocks in grid\n","    gridSize = (int)ceil((float)n/blockSize);\n"," \n","    // Execute the kernel\n","    vecAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n"," \n","    // Copy array back to host\n","    cudaMemcpy( h_c, d_c, bytes, cudaMemcpyDeviceToHost );\n"," \n","    // Sum up vector c and print result divided by n, this should equal 1 within error\n","    double sum = 0;\n","    for(i=0; i<n; i++)\n","        sum += h_c[i];\n","    printf(\"Sum: %f\\n\", sum/n);\n"," \n","    // Release device memory\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n"," \n","    // Release host memory\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","}\n","\n","void matMul(){\n","  int *h_a, *h_b, *h_c;\n","  int *d_a, *d_b, *d_c;\n","\n","  int size=sizeof(int)*N*N;\n","  cudaEvent_t start,end;\n","  float time=0;\n","  h_a=(int*)malloc(size);\n","  h_b=(int*)malloc(size);\n","  h_c=(int*)malloc(size);\n","  cudaEventCreate(&start);\n","  cudaEventCreate(&end);\n","  cudaEventRecord(start);\n","\n","  cudaMalloc(&d_a, size);\n","  cudaMalloc(&d_b, size);\n","  cudaMalloc(&d_c, size);\n","\n","  for (int i = 0; i < N*N; i++){\n"," \t  h_a[i] = random() % N;\n"," \t  h_b[i] = random() % N;\n","  }\n","\n","  printf(\"\\nMatrix A =>\\n\\n\");\n","  for (int i = 0; i < N; i++){\n","    for(int j = 0;j<N; j++){\n","      printf(\"%d \",h_a[i*N + j]);\n","    }\n"," \t  printf(\"\\n\");\n","   }\n","\n","  printf(\"\\nMatrix B =>\\n\\n\");\n","   for (int i = 0; i < N; i++){\n","      for(int j = 0;j<N; j++){\n","        printf(\"%d \",h_b[i*N + j]);\n","      }\n","      printf(\"\\n\");\n","    }\n","\n","\n","\n","  cudaMemcpy( d_a, h_a, size, cudaMemcpyHostToDevice);\n","  cudaMemcpy( d_b, h_b, size, cudaMemcpyHostToDevice);\n","\n","  int BLOCK_SIZE=N / TPB;\n","\n","  dim3 GridSize(BLOCK_SIZE, BLOCK_SIZE);\n","  dim3 BlockSize(TPB, TPB);\n","\n","  matrixMultiplication<<<GridSize,BlockSize>>>(d_a, d_b, d_c, N);\n","\n","  cudaMemcpy( h_c, d_c, size, cudaMemcpyDeviceToHost );\n","  cudaEventRecord(end);\n","  cudaEventSynchronize(end);\n","  cudaEventElapsedTime(&time,start,end);\n","  printf(\"\\nMatrix C =>\\n\\n\");\n","\n","  for (int i = 0; i < N; i++){\n","    for(int j = 0;j<N; j++){\n","      printf(\"%d \",h_c[i*N + j]);\n","    }\n","    printf(\"\\n\");\n","  }\n","\n","  printf(\"Time taken to perform %d by %d matrix mul is: %lf ms\",N,N,time);\n","\n","   cudaFree(d_a);\n","   cudaFree(d_b);\n","   cudaFree(d_c);\n","\n","   free(h_a);\n","   free(h_b);\n","   free(h_c);\n","}\n","\n","\n","int main( int argc, char* argv[] )\n","{\n","    printf(\"Add two large vectors \\n\");\n","    vecAdd();    \n","    //printf(\"\\n\\n\\n Multiply Vector and Matrix \\n\");    \n","    printf(\"\\n\\n\\n Multiply two N × N arrays using n2 processors\\n\");\n","    matMul();\n"," return 0;\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Add two large vectors \n","Sum: 99999.000000\n","\n","\n","\n"," Multiply two N × N arrays using n2 processors\n","\n","Matrix A =>\n","\n","3 1 1 2 \n","1 2 2 3 \n","0 0 3 3 \n","2 2 3 1 \n","\n","Matrix B =>\n","\n","2 3 3 0 \n","1 3 3 2 \n","2 0 0 1 \n","2 3 3 2 \n","\n","Matrix C =>\n","\n","13 18 18 7 \n","14 18 18 12 \n","12 9 9 9 \n","14 15 15 9 \n","Time taken to perform 4 by 4 matrix mul is: 0.151904 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-TyI5M2rdfa8"},"source":["#**OpenMP**"]},{"cell_type":"markdown","metadata":{"id":"PkcsOjHzQ2KK"},"source":["# **Assignment 3** : OpenMp\n","Parallel Sorting Algorithms for Bubble Sort and Merger Sort, based on existing sequential algorithms, design and implement parallel algorithm utilizing all resources available.\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBBgGj_hnKfR","outputId":"7ea8da70-711b-44ef-86f1-2fb2ff46553d"},"source":["%%cu\n","#include <iostream>\n","#include <omp.h>\n","using namespace std;\n","\n","void bubblesort(int a[],int n){\n","  for (int i = 0; i < n; i++) {\n","    int first = i%2;\n","    #pragma omp parallel for shared(a,first)\n","    for (int j = first; j < n-1; j+=2) {\n","        if (a[j] > a[j+1]) {\n","          int temp = a[j+1];\n","          a[j+1] = a[j];\n","          a[j] = temp;\n","      }\n","    }\n","  }\n","  cout<<\"Sorted list:\\n\";\n","  for (int i = 0; i < n; i++) {\n","    cout<<a[i]<<\"\\n\";\n","  }\n","}\n","\n","int main(){\n","  int n;\n","  clock_t t1,t2;\n","  cout<<\"Enter total number of elements:\\n\";\n","  //cin>>n;\n","  n=100;\n","  int a[n];\n","  cout<<\"Storing elements in descending order....\\n\\n\";\n","  for(int i = 0 ; i < n; i++){\n","    a[i] = n-i;\n","  }\n","  cout<<\"Actual list:\\n\";\n","  for (int i = 0; i < n; i++) {\n","    cout<<a[i]<<\"\\n\";\n","  }\n","  cout<<\"\\n\";\n","  t1 = clock();\n","  bubblesort(a,n);\n","  t2 = clock();\n","  //cout<<t1;\n","  \n","  printf(\"\\nExecution Time:%f\",(double)(t2-t1)/CLOCKS_PER_SEC);\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Enter total number of elements:\n","Storing elements in descending order....\n","\n","Actual list:\n","100\n","99\n","98\n","97\n","96\n","95\n","94\n","93\n","92\n","91\n","90\n","89\n","88\n","87\n","86\n","85\n","84\n","83\n","82\n","81\n","80\n","79\n","78\n","77\n","76\n","75\n","74\n","73\n","72\n","71\n","70\n","69\n","68\n","67\n","66\n","65\n","64\n","63\n","62\n","61\n","60\n","59\n","58\n","57\n","56\n","55\n","54\n","53\n","52\n","51\n","50\n","49\n","48\n","47\n","46\n","45\n","44\n","43\n","42\n","41\n","40\n","39\n","38\n","37\n","36\n","35\n","34\n","33\n","32\n","31\n","30\n","29\n","28\n","27\n","26\n","25\n","24\n","23\n","22\n","21\n","20\n","19\n","18\n","17\n","16\n","15\n","14\n","13\n","12\n","11\n","10\n","9\n","8\n","7\n","6\n","5\n","4\n","3\n","2\n","1\n","\n","Sorted list:\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","\n","Execution Time:0.000050\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xi-ZolAdQ6j6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8064b1f-5e08-419a-c0f6-d562a574729b"},"source":["%%cu\n","#include<iostream>\n","#include<omp.h>\n","using namespace std;\n","\n","void merge(int arr[], int l, int m, int r)\n","{\n","\tint i, j, k;\n","\tint n1 = m - l + 1;\n","\tint n2 = r - m;\n","\n","\tint L[n1], R[n2];\n","\n","\tfor (i = 0; i < n1; i++)\n","\t\tL[i] = arr[l + i];\n","\tfor (j = 0; j < n2; j++)\n","\t\tR[j] = arr[m + 1 + j];\n","\n","\ti = 0;\n","\tj = 0;\n","\tk = l;\n","\twhile (i < n1 && j < n2)\n","\t{\n","\t\tif (L[i] <= R[j])\n","\t\t{\n","\t\t\tarr[k] = L[i];\n","\t\t\ti++;\n","\t\t}\n","\t\telse\n","\t\t{\n","\t\t\tarr[k] = R[j];\n","\t\t\tj++;\n","\t\t}\n","\t\tk++;\n","\t}\n","\n","\n","\twhile (i < n1)\n","\t{\n","\t\tarr[k] = L[i];\n","\t\ti++;\n","\t\tk++;\n","\t}\n","\n","\n","\twhile (j < n2)\n","\t{\n","\t\tarr[k] = R[j];\n","\t\tj++;\n","\t\tk++;\n","\t}\n","}\n","\n","\n","void mergeSort(int arr[], int l, int r)\n","{\n","\tif (l < r)\n","\t{\n","\t\tint m = l+(r-l)/2;\n","    #pragma omp parallel sections\n","    {\n","      #pragma omp section\n","      {\n","        mergeSort(arr, l, m);\n","      }\n","      #pragma omp section\n","      {\n","        mergeSort(arr, m+1, r);\n","      }\n","    }\n","\t\tmerge(arr, l, m, r);\n","\t}\n","}\n","\n","void printArray(int A[], int size)\n","{\n","\tint i;\n","\tfor (i=0; i < size; i++)\n","\t\tcout<<A[i]<<\" \";\n","  cout<<\"\\n\";\n","}\n","\n","int main()\n","{\n","  int n;\n","  clock_t t1,t2;\n","  cout<<\"Enter total number of elements:\\n\";\n","  cin>>n;\n","  n=199;\n","  int a[n];\n","  cout<<\"Storing elements in descending order....\\n\\n\";\n","  for(int i = 0 ; i < n; i++){\n","    a[i] = n-i;\n","  }\n","\n","  cout<<\"Actual list:\\n\";\n","\tprintArray(a, n);\n","  t1 = clock();\n","\tmergeSort(a, 0, n - 1);\n","  t2 = clock();\n","  cout<<\"Sorted list:\\n\";\n","\tprintArray(a, n);\n","\n","  printf(\"\\nExecution Time:%f\",(double)(t2-t1)/CLOCKS_PER_SEC);\n","  return 0;\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Enter total number of elements:\n","Storing elements in descending order....\n","\n","Actual list:\n","199 198 197 196 195 194 193 192 191 190 189 188 187 186 185 184 183 182 181 180 179 178 177 176 175 174 173 172 171 170 169 168 167 166 165 164 163 162 161 160 159 158 157 156 155 154 153 152 151 150 149 148 147 146 145 144 143 142 141 140 139 138 137 136 135 134 133 132 131 130 129 128 127 126 125 124 123 122 121 120 119 118 117 116 115 114 113 112 111 110 109 108 107 106 105 104 103 102 101 100 99 98 97 96 95 94 93 92 91 90 89 88 87 86 85 84 83 82 81 80 79 78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 \n","Sorted list:\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 \n","\n","Execution Time:0.000031\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IY1qo0E4Q7OR"},"source":["# **Assignment 4** : OpenMp\n","\n","Parallel Search Algorithm-\n","\n","Design and implement parallel algorithm utilizing all resources available. For\n","1. Binary Search for Sorted Array\n","2. Depth-First Search (tree or an undirected graph ) : by us\n","3. Breadth-First Search ( tree or an undirected graph)"]},{"cell_type":"code","metadata":{"id":"F2mBUSP1Q7sq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"660a118f-58fd-48a4-bdf1-2d628e0b38b1"},"source":["%%cu\n","#include<iostream>\n","#include<omp.h>\n","#include<time.h>\n","using namespace std;\n","\n","int binary_search(int a[],int low,int high,int key){\n","  int loc = -1;\n","  int mid;\n","  while(low<=high){\n","    mid = (high + low )/2;\n","    if (a[mid] == key) {\n","      loc = mid;\n","      break;\n","    }\n","    else {\n","      #pragma omp parallel sections\n","      {\n","        #pragma omp section\n","        {\n","          if(a[mid]<key){\n","            low = mid+1;\n","          }\n","        }\n","        #pragma omp section\n","        {\n","          if(a[mid]>key){\n","            high = mid-1;\n","          }\n","        }\n","      }\n","    }\n","  }\n","  return loc;\n","}\n","\n","int main(){\n","\n","  int a[1000000];\n","  clock_t t1,t2;\n","  int key = 0;\n","  int loc,i;\n","  for (int i = 0; i < 1000000; i++) {\n","    a[i] = i;\n","  }\n","  cout<<\"Enter key to search: \\n\";\n","  //cin>>key;\n","  key = 56798;\n","  t1 = clock();\n","  loc = binary_search(a,0,1000000,key);\n","  t2 = clock();\n","  if (loc == -1) {\n","    cout<<\"Key not found\\n\";\n","  } else {\n","    cout<<\"Key found at \"<<loc<<\"\\n\";\n","   // cout<<\"Running thread \"<<omp_get_thread_num()<<\"\\n\";\n","  }\n","  //cout<<\"Execution time: \"<<t1<<\"\\t\"<<t2<<\"\\t\"<<t2-t1<<\"\\n\";\n","  printf(\"\\nExecution Time:%f\",(double)(t2-t1)/CLOCKS_PER_SEC);\n","\n","  return 0 ;\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Enter key to search: \n","Key found at 56798\n","\n","Execution Time:0.000002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ip7U_0RoQDq"},"source":[""],"execution_count":null,"outputs":[]}]}